// Function to create discrete beta distribution
var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var granularity = 20
var midBins = map(function(x) {roundTo3(x/granularity + 1/(2*granularity))}, 
                  _.range(0,granularity))

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})

// Is this a world in which the conventionally habitual activity is
// habitual (presumed cashier-payer) or non-habitual (presumed non-payer)?
// (mostly for demonstration)
var world = ["wonky","ordinary"]

// Assume uniform likelihood
var worldPrior = function() {
  categorical([0.5, 0.5], world)
}

// Habituality priors
// beta distributions fit to empirical priors
var habitualityPrior = function(world) {
  world === "ordinary" ? sample(DiscreteBeta(beta_high_a, beta_high_b)) :
  world === "wonky" ? sample(DiscreteBeta(beta_low_a, beta_low_b)) :
  true
}

// Current activity state
// the activity being described at this point in time either took place, or didn't
var state = ["happened","didn't happen"]

// State priors
// whether the activity took place is dependent on prior likelihood
var statePrior = function(habituality) {
  flip(habituality) ? state[0] : state[1]
}

// Utterances (intended)
// choice of 4 utterances; prosody not modeled separately as affects only one variant
var utterance = ['oh yeah','exclamation','plain','(...)']

// Utterance cost
// rough estimate of relative costs given number of consituents + articulatory effort
var cost = {
  "oh yeah": 4.5,
  "exclamation": 4,
  "plain": 3,
  "(...)": 0
}

// Utterances (recalled/attended to)
// assume that utterance most likely to be recalled as itself, but also has
// non-trivial likelihood of being recalled as 'neighboring' utterance
// (with markers for plain utterance; vice versa; no utterance for "plain"
// utterance; and vice versa).
// alternately, this can be conceptualized as listener's belief of what the speaker
// *intended* to say - but unclear if below is best way to represent that
var oh_yeah = [0.97,0.01,0.02,0.0001]
var exclamation = [0.01,0.97,0.02,0.0001]
var plain = [0.02,0.02,0.95,0.01]
var zero = [0.0001,0.0001,0.001,1]

var utterance_r = function(u_i) {
  u_i === "oh yeah" ? categorical(oh_yeah, utterance) :
  u_i === "exclamation" ? categorical(exclamation, utterance) :
  u_i === "plain" ? categorical(plain, utterance) :
  u_i === "(...)" ? categorical(zero, utterance) :
  true
}

// Confusion matrix for purpose of summing up probabilities
var utterance_r_prob = function(u_i, u_r) {
  u_i === "oh yeah" ? oh_yeah[_.indexOf(utterance, u_r)] :
  u_i === "exclamation" ? exclamation[_.indexOf(utterance, u_r)] :
  u_i === "plain" ? plain[_.indexOf(utterance, u_r)] :
  u_i === "(...)" ? zero[_.indexOf(utterance, u_r)] :
  true
}

// Meaning
// literal meaning of all overt utterances is that activity happened.
// literal meaning of null "utterance" is consistent with all activity states
var meaning = function(utterance,state) {
  utterance === "oh yeah" ? state === "happened" : 
  utterance === "exclamation" ? state === "happened" : 
  utterance === "plain" ? state === "happened" : 
  utterance === "(...)" ? true :
  true
}

// Speaker optimality (maximizing utility)
var alpha = 100

// Speaker optimality (minimizing cost)
var lambda = 1

// Utterance prior
// utterance prior determined by utterance cost, as defined above
var utterancePrior = function() {
  var uttProbs = map(function(u) {return Math.exp(-lambda * cost[u])}, utterance)
  return categorical(uttProbs, utterance)
}

// Utterance posterior P(u_r | u_i)
var utterancePosterior = mem(function(u_r) {
  Infer({method: 'enumerate', model: function() {
    var u_i = utterancePrior()
    condition(u_r === utterance_r(u_i))
    return u_i
  }})
})

// Literal listener
var literalListener = mem(function(u_r, habituality) {
  return Infer({method: 'enumerate', model: function() {
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    condition(meaning(u_i, state))
    return state
  }})
})

// Expected utilities
var get_EUs = function(u_i, state, habituality){
  var EUs = sum(map(function(u_r) {
    utterance_r_prob(u_i, u_r) *
      literalListener(u_r, habituality).score(state)
    }, utterance))
  return EUs
}

// Speaker
var speaker = mem(function(state, habituality) {
  return Infer({method: 'enumerate', model: function() {
    var u_i = utterancePrior()
    var EUs = get_EUs(u_i, state, habituality)
    factor(alpha * EUs)
    return u_i
  }})
})

// Pragmatic listener
// assume particular world for demonstration
var pragmaticListener = function(u_r, info) {
  return Infer({method: 'enumerate', model: function() {
    var world = world_type
    var habituality = habitualityPrior(world)
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    observe(speaker(state, habituality),u_i)
    info === "both" ? {state: state, habituality: habituality} :
    info === "state" ? state :
    info === "habituality" ? habituality :
    true
  }})
}


// viz(literalListener("(...)",0.95))
// viz(literalListener("(...)",0.5))
// viz(literalListener("(...)",0.05))

// viz(speaker("happened",0.95))
// viz(speaker("happened",0.5))
// viz(speaker("happened",0.05))

// viz(pragmaticListener("(...)","habituality"))
// viz(pragmaticListener("plain","habituality"))
// viz(pragmaticListener("exclamation","habituality"))
// viz(pragmaticListener("oh yeah","habituality"))