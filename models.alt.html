<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Modeling pragmatic inferences triggered by informational redundancy: Alternative models</title>

<script src="models.alt_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="models.alt_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="models.alt_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="models.alt_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="models.alt_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="models.alt_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="models.alt_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="models.alt_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="models.alt_files/navigation-1.1/tabsets.js"></script>
<link href="models.alt_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="models.alt_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Modeling pragmatic inferences triggered by informational redundancy: Alternative models</h1>

</div>


<div id="almost-cant-be-misremembered" class="section level2">
<h2>“(…)” (almost) can’t be misremembered</h2>
<p>Making zero utterance almost impossible to misremember breaks the model.</p>
<pre class="js"><code>var beta_high_a = 2.196026
var beta_high_b = 0.410857
var beta_low_a = 0.902843
var beta_low_b = 1.367937

var world_type = &quot;ordinary&quot;

// Function to create discrete beta distribution
var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var granularity = 20
var midBins = map(function(x) {roundTo3(x/granularity + 1/(2*granularity))}, 
                  _.range(0,granularity))

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})

// Is this a world in which the conventionally habitual activity is
// habitual (presumed cashier-payer) or non-habitual (presumed non-payer)?
// (mostly for demonstration)
var world = [&quot;wonky&quot;,&quot;ordinary&quot;]

// Assume uniform likelihood
var worldPrior = function() {
  categorical([0.5, 0.5], world)
}

// Habituality priors
// beta distributions fit to empirical priors
var habitualityPrior = function(world) {
  world === &quot;ordinary&quot; ? sample(DiscreteBeta(beta_high_a, beta_high_b)) :
  world === &quot;wonky&quot; ? sample(DiscreteBeta(beta_low_a, beta_low_b)) :
  true
}

// Current activity state
// the activity being described at this point in time either took place, or didn&#39;t
var state = [&quot;happened&quot;,&quot;didn&#39;t happen&quot;]

// State priors
// whether the activity took place is dependent on prior likelihood
var statePrior = function(habituality) {
  flip(habituality) ? state[0] : state[1]
}

// Utterances (intended)
// choice of 4 utterances; prosody not modeled separately as affects only one variant
var utterance = [&#39;oh yeah&#39;,&#39;exclamation&#39;,&#39;plain&#39;,&#39;(...)&#39;]

// Utterance cost
// rough estimate of relative costs given number of consituents + articulatory effort
var cost = {
  &quot;oh yeah&quot;: 4.5,
  &quot;exclamation&quot;: 4,
  &quot;plain&quot;: 3,
  &quot;(...)&quot;: 0
}

// Utterances (recalled/attended to)
// assume that utterance most likely to be recalled as itself, but also has
// non-trivial likelihood of being recalled as &#39;neighboring&#39; utterance
// (with markers for plain utterance; vice versa; no utterance for &quot;plain&quot;
// utterance; and vice versa).
// alternately, this can be conceptualized as listener&#39;s belief of what the speaker
// *intended* to say - but unclear if below is best way to represent that
var oh_yeah = [0.97,0.01,0.02,0.0001]
var exclamation = [0.01,0.97,0.02,0.0001]
var plain = [0.02,0.02,0.95,0.01]
var zero = [0.0001,0.0001,0.0001,1]

var utterance_r = function(u_i) {
  u_i === &quot;oh yeah&quot; ? categorical(oh_yeah, utterance) :
  u_i === &quot;exclamation&quot; ? categorical(exclamation, utterance) :
  u_i === &quot;plain&quot; ? categorical(plain, utterance) :
  u_i === &quot;(...)&quot; ? categorical(zero, utterance) :
  true
}

// Confusion matrix for purpose of summing up probabilities
var utterance_r_prob = function(u_i, u_r) {
  u_i === &quot;oh yeah&quot; ? oh_yeah[_.indexOf(utterance, u_r)] :
  u_i === &quot;exclamation&quot; ? exclamation[_.indexOf(utterance, u_r)] :
  u_i === &quot;plain&quot; ? plain[_.indexOf(utterance, u_r)] :
  u_i === &quot;(...)&quot; ? zero[_.indexOf(utterance, u_r)] :
  true
}

// Meaning
// literal meaning of all overt utterances is that activity happened.
// literal meaning of null &quot;utterance&quot; is consistent with all activity states
var meaning = function(utterance,state) {
  utterance === &quot;oh yeah&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;exclamation&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;plain&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;(...)&quot; ? true :
  true
}

// Speaker optimality (maximizing utility)
var alpha = 100

// Speaker optimality (minimizing cost)
var lambda = 1

// Utterance prior
// utterance prior determined by utterance cost, as defined above
var utterancePrior = function() {
  var uttProbs = map(function(u) {return Math.exp(-lambda * cost[u])}, utterance)
  return categorical(uttProbs, utterance)
}

// Utterance posterior P(u_r | u_i)
var utterancePosterior = mem(function(u_r) {
  Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior()
    condition(u_r === utterance_r(u_i))
    return u_i
  }})
})

// Literal listener
var literalListener = mem(function(u_r, habituality) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    condition(meaning(u_i, state))
    return state
  }})
})

// Expected utilities
var get_EUs = function(u_i, state, habituality){
  var EUs = sum(map(function(u_r) {
    utterance_r_prob(u_i, u_r) *
      literalListener(u_r, habituality).score(state)
    }, utterance))
  return EUs
}

// Speaker
var speaker = mem(function(state, habituality) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior()
    var EUs = get_EUs(u_i, state, habituality)
    factor(alpha * EUs)
    return u_i
  }})
})

// Pragmatic listener
// assume particular world for demonstration
var pragmaticListener = function(u_r, info) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var world = world_type
    var habituality = habitualityPrior(world)
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    observe(speaker(state, habituality),u_i)
    info === &quot;both&quot; ? {state: state, habituality: habituality} :
    info === &quot;state&quot; ? state :
    info === &quot;habituality&quot; ? habituality :
    true
  }})
}


// viz(literalListener(&quot;(...)&quot;,0.95))
// viz(literalListener(&quot;(...)&quot;,0.5))
// viz(literalListener(&quot;(...)&quot;,0.05))

// viz(speaker(&quot;happened&quot;,0.95))
// viz(speaker(&quot;happened&quot;,0.5))
// viz(speaker(&quot;happened&quot;,0.05))

// viz(pragmaticListener(&quot;(...)&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;plain&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;exclamation&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;oh yeah&quot;,&quot;habituality&quot;))</code></pre>
<div id="results" class="section level3">
<h3>Results</h3>
<div id="literal-listener" class="section level4">
<h4>Literal listener</h4>
<p><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%201-1.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%201-2.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%201-3.png" width="672" /></p>
</div>
<div id="speaker" class="section level4">
<h4>Speaker</h4>
<p><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%202-1.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%202-2.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%202-3.png" width="672" /></p>
</div>
<div id="pragmatic-listener" class="section level4">
<h4>Pragmatic listener</h4>
<p><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-1.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-2.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-3.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-4.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-5.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-6.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-7.png" width="672" /><img src="models.alt_files/figure-html/null%20noisy%20hRSA%20plots%203-8.png" width="672" /></p>
</div>
</div>
<div id="comparison-to-empirical-results" class="section level3">
<h3>Comparison to empirical results</h3>
<p><img src="models.alt_files/figure-html/null%20empirical%20results%201-1.png" width="672" /></p>
<p><img src="models.alt_files/figure-html/null%20empirical%20results%202-1.png" width="672" /></p>
</div>
</div>
<div id="extremely-unlikely-to-be-misremembered" class="section level2">
<h2>“(…)” extremely unlikely to be misremembered</h2>
<p>Making zero utterance extremely unlikely to be misremembered breaks the model, unless utility-maximizing optimality set extremely high.</p>
<pre class="js"><code>var beta_high_a = 2.196026
var beta_high_b = 0.410857
var beta_low_a = 0.902843
var beta_low_b = 1.367937

var world_type = &quot;ordinary&quot;

// Function to create discrete beta distribution
var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var granularity = 20
var midBins = map(function(x) {roundTo3(x/granularity + 1/(2*granularity))}, 
                  _.range(0,granularity))

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})

// Is this a world in which the conventionally habitual activity is
// habitual (presumed cashier-payer) or non-habitual (presumed non-payer)?
// (mostly for demonstration)
var world = [&quot;wonky&quot;,&quot;ordinary&quot;]

// Assume uniform likelihood
var worldPrior = function() {
  categorical([0.5, 0.5], world)
}

// Habituality priors
// beta distributions fit to empirical priors
var habitualityPrior = function(world) {
  world === &quot;ordinary&quot; ? sample(DiscreteBeta(beta_high_a, beta_high_b)) :
  world === &quot;wonky&quot; ? sample(DiscreteBeta(beta_low_a, beta_low_b)) :
  true
}

// Current activity state
// the activity being described at this point in time either took place, or didn&#39;t
var state = [&quot;happened&quot;,&quot;didn&#39;t happen&quot;]

// State priors
// whether the activity took place is dependent on prior likelihood
var statePrior = function(habituality) {
  flip(habituality) ? state[0] : state[1]
}

// Utterances (intended)
// choice of 4 utterances; prosody not modeled separately as affects only one variant
var utterance = [&#39;oh yeah&#39;,&#39;exclamation&#39;,&#39;plain&#39;,&#39;(...)&#39;]

// Utterance cost
// rough estimate of relative costs given number of consituents + articulatory effort
var cost = {
  &quot;oh yeah&quot;: 4.5,
  &quot;exclamation&quot;: 4,
  &quot;plain&quot;: 3,
  &quot;(...)&quot;: 0
}

// Utterances (recalled/attended to)
// assume that utterance most likely to be recalled as itself, but also has
// non-trivial likelihood of being recalled as &#39;neighboring&#39; utterance
// (with markers for plain utterance; vice versa; no utterance for &quot;plain&quot;
// utterance; and vice versa).
// alternately, this can be conceptualized as listener&#39;s belief of what the speaker
// *intended* to say - but unclear if below is best way to represent that
var oh_yeah = [0.97,0.01,0.02,0.0001]
var exclamation = [0.01,0.97,0.02,0.0001]
var plain = [0.02,0.02,0.95,0.01]
var zero = [0.0001,0.0001,0.001,1]

var utterance_r = function(u_i) {
  u_i === &quot;oh yeah&quot; ? categorical(oh_yeah, utterance) :
  u_i === &quot;exclamation&quot; ? categorical(exclamation, utterance) :
  u_i === &quot;plain&quot; ? categorical(plain, utterance) :
  u_i === &quot;(...)&quot; ? categorical(zero, utterance) :
  true
}

// Confusion matrix for purpose of summing up probabilities
var utterance_r_prob = function(u_i, u_r) {
  u_i === &quot;oh yeah&quot; ? oh_yeah[_.indexOf(utterance, u_r)] :
  u_i === &quot;exclamation&quot; ? exclamation[_.indexOf(utterance, u_r)] :
  u_i === &quot;plain&quot; ? plain[_.indexOf(utterance, u_r)] :
  u_i === &quot;(...)&quot; ? zero[_.indexOf(utterance, u_r)] :
  true
}

// Meaning
// literal meaning of all overt utterances is that activity happened.
// literal meaning of null &quot;utterance&quot; is consistent with all activity states
var meaning = function(utterance,state) {
  utterance === &quot;oh yeah&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;exclamation&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;plain&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;(...)&quot; ? true :
  true
}

// Speaker optimality (maximizing utility)
var alpha = 100

// Speaker optimality (minimizing cost)
var lambda = 1

// Utterance prior
// utterance prior determined by utterance cost, as defined above
var utterancePrior = function() {
  var uttProbs = map(function(u) {return Math.exp(-lambda * cost[u])}, utterance)
  return categorical(uttProbs, utterance)
}

// Utterance posterior P(u_r | u_i)
var utterancePosterior = mem(function(u_r) {
  Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior()
    condition(u_r === utterance_r(u_i))
    return u_i
  }})
})

// Literal listener
var literalListener = mem(function(u_r, habituality) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    condition(meaning(u_i, state))
    return state
  }})
})

// Expected utilities
var get_EUs = function(u_i, state, habituality){
  var EUs = sum(map(function(u_r) {
    utterance_r_prob(u_i, u_r) *
      literalListener(u_r, habituality).score(state)
    }, utterance))
  return EUs
}

// Speaker
var speaker = mem(function(state, habituality) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior()
    var EUs = get_EUs(u_i, state, habituality)
    factor(alpha * EUs)
    return u_i
  }})
})

// Pragmatic listener
// assume particular world for demonstration
var pragmaticListener = function(u_r, info) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var world = world_type
    var habituality = habitualityPrior(world)
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r))
    observe(speaker(state, habituality),u_i)
    info === &quot;both&quot; ? {state: state, habituality: habituality} :
    info === &quot;state&quot; ? state :
    info === &quot;habituality&quot; ? habituality :
    true
  }})
}


// viz(literalListener(&quot;(...)&quot;,0.95))
// viz(literalListener(&quot;(...)&quot;,0.5))
// viz(literalListener(&quot;(...)&quot;,0.05))

// viz(speaker(&quot;happened&quot;,0.95))
// viz(speaker(&quot;happened&quot;,0.5))
// viz(speaker(&quot;happened&quot;,0.05))

// viz(pragmaticListener(&quot;(...)&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;plain&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;exclamation&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;oh yeah&quot;,&quot;habituality&quot;))</code></pre>
<div id="results-1" class="section level3">
<h3>Results</h3>
<div id="literal-listener-1" class="section level4">
<h4>Literal listener</h4>
<p><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%201-1.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%201-2.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%201-3.png" width="672" /></p>
</div>
<div id="speaker-1" class="section level4">
<h4>Speaker</h4>
<p><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%202-1.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%202-2.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%202-3.png" width="672" /></p>
</div>
<div id="pragmatic-listener-1" class="section level4">
<h4>Pragmatic listener</h4>
<p><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-1.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-2.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-3.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-4.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-5.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-6.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-7.png" width="672" /><img src="models.alt_files/figure-html/null%20diff%20noisy%20hRSA%20plots%203-8.png" width="672" /></p>
</div>
</div>
<div id="comparison-to-empirical-results-1" class="section level3">
<h3>Comparison to empirical results</h3>
<p><img src="models.alt_files/figure-html/null%20diff%20empirical%20results%201-1.png" width="672" /></p>
<p><img src="models.alt_files/figure-html/null%20diff%20empirical%20results%202-1.png" width="672" /></p>
</div>
</div>
<div id="threshold" class="section level2">
<h2>Threshold</h2>
<!-- ![](board.jpg) -->
<ul>
<li><span class="math inline">\(P_{L_0}(s|u,\boldsymbol\theta,h) \propto P(s|[\![m]\!]^{\boldsymbol\theta,h})\)</span></li>
<li><span class="math inline">\(P_{S_1}(u|s,\boldsymbol\theta,h;\alpha,\lambda,C) \propto P(u;\lambda,C)\exp(\alpha\log P_{L_0}(s|u,\boldsymbol\theta,h))\)</span></li>
<li><span class="math inline">\(P_{L_1}(s,\boldsymbol\theta,h|u) \propto P_{S_1}(u|s,\boldsymbol\theta,h;\alpha,\lambda,C) \cdot P(\boldsymbol\theta) \cdot P(s|h) \cdot P(h)\)</span></li>
</ul>
<pre class="js"><code>var beta_high_a = 2.196026
var beta_high_b = 0.410857
var beta_low_a = 0.902843
var beta_low_b = 1.367937
var alpha_value = 1
var lambda_value = 100

var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var granularity = 20
var midBins = map(function(x) {roundTo3(x/granularity + 1/(2*granularity))}, 
                  _.range(0,granularity))

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        // var xi = x &gt;= 1 ? 0.99 : x == 0 ? 0.01 : x
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})

// Activity type
var activityType = [&quot;habitual&quot;,&quot;non-habitual&quot;]

// Activity type prior
var activityTypePrior = function() {
  categorical([0.5, 0.5], activityType)
}

// Habituality priors
var habitualityPrior = function(activityType) {
  activityType === &quot;habitual&quot; ? sample(DiscreteBeta(beta_high_a, beta_high_b)) :
  activityType === &quot;non-habitual&quot; ? sample(DiscreteBeta(beta_low_a, beta_low_b)) :
  true
}

// Theta prior
var thetaPrior = function(activity) {
  var thetas = midBins
  return uniformDraw(thetas)
}

// Current activity state
var state = [&quot;happened&quot;,&quot;didn&#39;t happen&quot;]

// State priors
var statePrior = function(habituality) {
  flip(habituality) ? state[0] : state[1]
}

// Utterances
var utterance = [&#39;exclamation&#39;,&#39;plain&#39;,&#39;(...)&#39;]

// Utterance cost
var cost = {
  &quot;exclamation&quot;: 4,
  &quot;plain&quot;: 3,
  &quot;(...)&quot;: 0
}

// Meaning
var meaning = function(utterance,state,
                        thetaPlain,thetaExclamation,
                        habituality) {
  utterance === &quot;exclamation&quot; ? state === &quot;happened&quot; &amp;&amp; habituality &lt;= thetaExclamation : 
  utterance === &quot;plain&quot; ? state === &quot;happened&quot; &amp;&amp; habituality &lt;= thetaPlain : 
  utterance === &quot;(...)&quot; ? true :
  true
}

// Speaker optimality (utility)
var alpha = alpha_value

// Speaker optimality (cost)
var lambda = lambda_value

// Utterance prior
var utterancePrior = mem(function() {
  var uttProbs = map(function(u) {return Math.exp(-lambda*cost[u])}, utterance)
  return categorical(uttProbs, utterance)
})

// Literal listener
var literalListener = mem(function(utterance, 
                                   thetaPlain, thetaExclamation,
                                   activityType) {
  return Infer({method: &quot;enumerate&quot;, model: function() {
    var habituality = habitualityPrior(activityType) 
    var state = statePrior(habituality)
    condition(meaning(utterance, state, thetaPlain, thetaExclamation,
                        habituality))
    return {state, habituality} 
  }})
})

// Speaker
var speaker = mem(function(state, 
                            habituality, 
                            thetaPlain,
                            thetaExclamation,
                            activityType) {
  return Infer({method: &quot;enumerate&quot;, model: function() {
    var utterance = utterancePrior()
    factor(alpha * literalListener(utterance, thetaPlain, thetaExclamation, activityType).score({state, habituality}))
    return utterance
  }})
})

// Pragmatic listener
var pragmaticListener = mem(function(utterance, activityType) {
  return Infer({method: &quot;enumerate&quot;, model: function() {
    var habituality = habitualityPrior(activityType)
    var thetaPlain = thetaPrior()
    var thetaExclamation = thetaPrior()
    var state = statePrior(habituality)
    observe(speaker(state, habituality, thetaPlain, thetaExclamation,
                        activityType), utterance)
    return {state, habituality, thetaPlain, thetaExclamation}
  }})
})

// print(expectation(pragmaticListener(&quot;(...)&quot;, &quot;habitual&quot;)))
// print(expectation(pragmaticListener(&quot;plain&quot;, &quot;habitual&quot;)))
// print(expectation(pragmaticListener(&quot;exclamation&quot;, &quot;habitual&quot;)))</code></pre>
<div id="results-2" class="section level3">
<h3>Results</h3>
<div id="literal-listener-2" class="section level4">
<h4>Literal listener</h4>
<p><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%201-1.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%201-2.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%201-3.png" width="672" /></p>
</div>
<div id="speaker-2" class="section level4">
<h4>Speaker</h4>
<p><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%202-1.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%202-2.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%202-3.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%202-4.png" width="672" /></p>
</div>
<div id="pragmatic-listener-2" class="section level4">
<h4>Pragmatic listener</h4>
<p><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-1.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-2.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-3.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-4.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-5.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-6.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-7.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-8.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-9.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-10.png" width="672" /><img src="models.alt_files/figure-html/threshold%20hRSA%20plots%203-11.png" width="672" /></p>
</div>
</div>
<div id="comparison-to-empirical-results-2" class="section level3">
<h3>Comparison to empirical results</h3>
<p><img src="models.alt_files/figure-html/threshold%20empirical%20results%201-1.png" width="672" /></p>
<p><img src="models.alt_files/figure-html/threshold%20empirical%20results%202-1.png" width="672" /></p>
</div>
</div>
<div id="reasoning-about-speaker-optimality" class="section level2">
<h2>Reasoning about speaker optimality</h2>
<pre class="js"><code>// Function to create discrete beta distribution
var roundTo3 = function(x){
  return Math.round(x * 1000) / 1000
}

var granularity = 20
var midBins = map(function(x) {roundTo3(x/granularity + 1/(2*granularity))}, 
                  _.range(0,granularity))

var DiscreteBeta = cache(function(a, b){
  Infer({model: function(){
    categorical({
      vs:midBins,
      ps:map(function(x){
        Math.exp(Beta({a, b}).score(x))
      }, midBins)
    })
  }})
})

// Is this a world in which the conventionally habitual activity is
// habitual (presumed cashier-payer) or non-habitual (presumed non-payer)?
// (mostly for demonstration)
var world = [&quot;wonky&quot;,&quot;ordinary&quot;]

// Assume uniform likelihood
var worldPrior = function() {
  categorical([0.5, 0.5], world)
}

// Habituality priors
// beta distributions fit to empirical priors
var habitualityPrior = function(world) {
  world === &quot;ordinary&quot; ? sample(DiscreteBeta(beta_high_a, beta_high_b)) :
  world === &quot;wonky&quot; ? sample(DiscreteBeta(beta_low_a, beta_low_b)) :
  true
}

// Current activity state
// the activity being described at this point in time either took place, or didn&#39;t
var state = [&quot;happened&quot;,&quot;didn&#39;t happen&quot;]

// State priors
// whether the activity took place is dependent on prior likelihood
var statePrior = function(habituality) {
  flip(habituality) ? state[0] : state[1]
}

// Utterances (intended)
// choice of 4 utterances; prosody not modeled separately as affects only one variant
var utterance = [&#39;oh yeah&#39;,&#39;exclamation&#39;,&#39;plain&#39;,&#39;(...)&#39;]

// Utterance cost
// rough estimate of relative costs given number of consituents + articulatory effort
var cost = {
  &quot;oh yeah&quot;: 4.5,
  &quot;exclamation&quot;: 4,
  &quot;plain&quot;: 3,
  &quot;(...)&quot;: 0
}

// Utterances (recalled/attended to)
// assume that utterance most likely to be recalled as itself, but also has
// non-trivial likelihood of being recalled as &#39;neighboring&#39; utterance
// (with markers for plain utterance; vice versa; no utterance for &quot;plain&quot;
// utterance; and vice versa).
// alternately, this can be conceptualized as listener&#39;s belief of what the speaker
// *intended* to say - but unclear if below is best way to represent that
var oh_yeah = [0.97,0.01,0.02,0.0001]
var exclamation = [0.01,0.97,0.02,0.0001]
var plain = [0.02,0.02,0.95,0.01]
var zero = [0.0001,0.0001,0.01,0.99]

var utterance_r = function(u_i) {
  u_i === &quot;oh yeah&quot; ? categorical(oh_yeah, utterance) :
  u_i === &quot;exclamation&quot; ? categorical(exclamation, utterance) :
  u_i === &quot;plain&quot; ? categorical(plain, utterance) :
  u_i === &quot;(...)&quot; ? categorical(zero, utterance) :
  true
}

// Confusion matrix for purpose of summing up probabilities
var utterance_r_prob = function(u_i, u_r) {
  u_i === &quot;oh yeah&quot; ? oh_yeah[_.indexOf(utterance, u_r)] :
  u_i === &quot;exclamation&quot; ? exclamation[_.indexOf(utterance, u_r)] :
  u_i === &quot;plain&quot; ? plain[_.indexOf(utterance, u_r)] :
  u_i === &quot;(...)&quot; ? zero[_.indexOf(utterance, u_r)] :
  true
}

// Meaning
// literal meaning of all overt utterances is that activity happened.
// literal meaning of null &quot;utterance&quot; is consistent with all activity states
var meaning = function(utterance,state) {
  utterance === &quot;oh yeah&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;exclamation&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;plain&quot; ? state === &quot;happened&quot; : 
  utterance === &quot;(...)&quot; ? true :
  true
}

// Speaker optimality (maximizing utility)
var alpha = [1,3,5,7,9,11,13,15,17,19]

var alphaPrior = function() {
  uniformDraw(alpha)
}

// Speaker optimality (minimizing cost)
var lambda = [1,3,5,7,9,11,13,15,17,19]

var lambdaPrior = function() {
  uniformDraw(lambda)
}

// Utterance prior
// utterance prior determined by utterance cost, as defined above
var utterancePrior = function(lambda) {
  var uttProbs = map(function(u) {return Math.exp(-lambda * cost[u])}, utterance)
  return categorical(uttProbs, utterance)
}

// Utterance posterior P(u_r | u_i)
var utterancePosterior = mem(function(u_r, lambda) {
  Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior(lambda)
    condition(u_r === utterance_r(u_i))
    return u_i
  }})
})

// Literal listener
var literalListener = mem(function(u_r, habituality, lambda) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var state = statePrior(habituality)
    var u_i = sample(utterancePosterior(u_r, lambda))
    condition(meaning(u_i, state))
    return state
  }})
})

// Expected utilities
var get_EUs = function(u_i, state, habituality, lambda){
  var EUs = sum(map(function(u_r) {
    utterance_r_prob(u_i, u_r) *
      literalListener(u_r, habituality, lambda).score(state)
    }, utterance))
  return EUs
}

// Speaker
var speaker = mem(function(state, habituality, alpha, lambda) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var u_i = utterancePrior(lambda)
    var EUs = get_EUs(u_i, state, habituality, lambda)
    factor(alpha * EUs)
    return u_i
  }})
})

// Pragmatic listener
// assume particular world for demonstration
var pragmaticListener = function(u_r) {
  return Infer({method: &#39;enumerate&#39;, model: function() {
    var world = world_type
    var habituality = habitualityPrior(world)
    var state = statePrior(habituality)
    var alpha = alphaPrior()
    var lambda = lambdaPrior()
    var u_i = sample(utterancePosterior(u_r, lambda))
    observe(speaker(state, habituality, alpha, lambda),u_i)
    return {state: state, habituality: habituality, alpha: alpha, lambda: lambda}
  }})
}


// viz(literalListener(&quot;(...)&quot;,0.95))
// viz(literalListener(&quot;(...)&quot;,0.5))
// viz(literalListener(&quot;(...)&quot;,0.05))

// viz(speaker(&quot;happened&quot;,0.95))
// viz(speaker(&quot;happened&quot;,0.5))
// viz(speaker(&quot;happened&quot;,0.05))

// viz(pragmaticListener(&quot;(...)&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;plain&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;exclamation&quot;,&quot;habituality&quot;))
// viz(pragmaticListener(&quot;oh yeah&quot;,&quot;habituality&quot;))</code></pre>
<hr />
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
